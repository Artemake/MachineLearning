{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Supervised Learning - Linear Models with 1-variable #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Representation ##\n",
    "\n",
    "%%latex\n",
    "<img src=\"../pictures/notation.png\" alt=\"notation\" width=\"800\" height=\"800\" />\n",
    "\n",
    "\n",
    "Ως $x^{(i)}$ ορίζουμε τις μεταβλητές εισόδου, που ονομάζονται και χαρακτηριστικά (features), και ως $y^{(i)}$ ορίζουμε τις μεταβλητές εξόδου, που ονομάζονται και μεταβλητές στόχοι (target), και τις οποίες προσπαθούμε να προβλέψουμε. Ένα ζευγάρι $(x^{(i)}$,$y^{(i)})$ ονομάζεται παράδειγμα εκπαίδευσης (training example), ενώ μια λίστα από $m$ παραδείγματα εκπαίδευσης $(x^{(i)}$,$y^{(i)})$; $i = 1,...,m$ ονομάζεται σύνολο εκπαίδευσης.\n",
    "\n",
    "\n",
    "<img src=\"../pictures/learning_process.png\" alt=\"learning_process\" width=\"800\" height=\"800\" />\n",
    "\n",
    "Για να περιγράψουμε τυπικά το πρόβλημα της μάθησης με επίβλεψη, στόχος είναι, ένα σύστημα να μάθει μια συνάρτηση $h: {X} -> y$ έτσι ώστε $h(x)$ να είναι μια καλή πρόβλεψη της αντίστοιχης τιμής $y$. Η συνάρτηση αυτή καλείται συνάρτηση υπόθεσης. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representation ###\n",
    "\n",
    "In linear regression, we represent the hypothesis, $h$, as follows:\n",
    "\n",
    "$$h_{\\theta}(x) = \\theta_{0} + \\theta_{1}x_1 + \\theta_{2} x_2 + \\dots  +  \\theta_{n} x_n$$\n",
    "\n",
    "$\\theta_0$ is called **bias** and $\\theta_1,\\theta_2,\\dots,\\theta_n$ are called feature weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation ###\n",
    "\n",
    "A loss function $L(h_{\\theta}(x),y)$ measures the difference between the value of the output variable $y$ of a training example ($x,y$) and the output of the hypothesis given $x$, $h_{\\theta}(x)$\n",
    "\n",
    "A cost function iterates over the training corpus $(x^{(i)},y^{(i)})$, $i=1...m$ and measures the average loss between the ground truth $y^{(i)}$ and the output of the hypothesis $h_{\\theta}(x^{(i)})$\n",
    "\n",
    "\n",
    "We evaluate linear regression hypotheses using the (half of) the mean squared error cost function: \n",
    "\n",
    "$$J(\\theta_0,\\dots,\\theta_n) = \\dfrac{1}{2m}\\sum_{i=1}^m[h_\\theta(x^{(i)}) - y^{(i)}]^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphical Representation\n",
    "\n",
    "The following plot represents training examples scattered across the plane $x-y$. \n",
    "\n",
    "<img src=\"../pictures/cost_function_1.png\" alt=\"notation\" width=\"500\" height=\"500\" />\n",
    "\n",
    "We try to find a straight line, which is defined by $h_{\\theta}(x) = \\theta_0 + \\theta_1x $, and will cross along all the points.\n",
    "\n",
    "The best straight line is the one where **mean squarred error** from all the examples (points) and the line will be minimum. Ideally, this line should go through all the data points. In such case $J(\\theta_0,\\theta_1) = 0$. The following figure displays the ideal case where the cost functions is equally to 0. \n",
    "\n",
    "<img src=\"../pictures/cost_function_2.png\" alt=\"notation\" width=\"500\" height=\"500\" />\n",
    "\n",
    "The cost is computed like this: \n",
    "\n",
    "$$J(\\theta_1) = \\dfrac{1}{2m}\\sum^m_{i=1}(h_{\\theta}(x^{(i)})-y^{(i)})^2 = \\dfrac{1}{2m}\\sum^m_{i=1}(\\theta_i x^{(i)}-y^{(i)})^2 = \\dfrac{1}{2m}(0^2 + 0^2 + 0^2) = 0$$\n",
    "\n",
    "\n",
    "In case where the $\\theta_1=0.5$, which the line's slope (κλίση), the vertical distance between the data points and the line is increased. The result is displayed in the following image:\n",
    "\n",
    "<img src=\"../pictures/cost_function_3_brushed.png\" alt=\"notation\" width=\"500\" height=\"500\" />\n",
    "\n",
    "The cost is alson increased:\n",
    "$$J(\\theta_1) = J(0.5) = \\dfrac{1}{2m}((0.5-1)^2 + (1-2)^2 + (1.5-3)^2) = \\dfrac{1}{2\\cdot3}(3.5) \\approx0.58$$\n",
    "\n",
    "\n",
    "Different values for $\\theta$ give different costs as depicted in the following figure:\n",
    "\n",
    "<img src=\"../pictures/cost_function_4.png\" alt=\"notation\" width=\"500\" height=\"500\" />\n",
    "\n",
    "\n",
    "The goal of linear regression is to **minimize the cost function**. In this case $\\theta_1=1$ is a global minimum. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent ##\n",
    "\n",
    "So we have our hypothesis function $h(x)$ and we have a way of measuring how well it fits into the data. Now we need to estimate the parameters in the hypothesis function. That's where **gradient descent** comes in.\n",
    "\n",
    "We have a function $J(\\theta_0,\\theta_1)$ and we want the minimum min$J(\\theta_0,\\theta_1)$. We start with some $\\theta_0$ & $\\theta_1$. We start let's say with $\\theta_0=0$ and $\\theta_1=0$ and we constantly changing until we hopefully reach a minimum. \n",
    "\n",
    "Imagine that we graph our hypothesis function based on its fields $\\theta_0$ & $\\theta_1$ (actually we are graphing the cost function as a function of the parameter estimates). We are not graphing $x$ and $y$ itself, but the parameter range of our hypothesis function and the cost resulting from selecting a particular set of parameters.\n",
    "\n",
    "We put $\\theta_0$ on the $x$ axis and $\\theta_1$ on the $y$ axis, with the cost function on the vertical $z$ axis. The points on our graph will be the result of the cost function using our hypothesis with those specific theta parameters. The graph below depicts such a setup.\n",
    "\n",
    "![](../pictures/gradient_1.png)\n",
    "\n",
    "We will know that we have succeeded when our cost function is at the very bottom of the pits in our graph, i.e. when its value is the minimum. The red arrows show the minimum points in the graph.\n",
    "\n",
    "The way we do this is by taking the derivative (the tangential line to a function) of our cost function. The slope of the tangent is the derivative at that point and it will give us a direction to move towards. We make steps down the cost function in the direction with the steepest descent. The size of each step is determined by the parameter $\\alpha$, which is called the **learning rate**. \n",
    "\n",
    "For example, the distance between each 'star' in the graph above represents a step determined by our parameter $\\alpha$. A smaller $\\alpha$ would result in a smaller step and a larger $\\alpha$ results in a larger step. The direction in which the step is taken is determined by the partial derivative of $J(\\theta_0,\\theta_1)$. Depending on where one starts on the graph, one could end up at different points. The image above shows us two different starting points that end up in two different places.\n",
    "\n",
    "\n",
    "Repeat until convergence:\n",
    "$$\\theta_j := \\theta_j -  \\alpha \\dfrac{\\partial}{\\partial\\theta_j}J(\\theta_0,\\theta_1)$$\n",
    "\n",
    "where $j=0,1$ represents the $j$th feature. In each iteration, parameters $\\theta_0,\\theta_1,\\dots,\\theta_n$ should be computed at the same time. Computing a parameter before another one will lead to errors.\n",
    "\n",
    "\n",
    "When specifically applied to the case of linear regression, a new form of the gradient descent equation can be derived. We can substitute our actual cost function and our actual hypothesis function and modify the equation to:\n",
    "\n",
    "\n",
    "$$\\theta_0 :=  \\theta_0 - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m}(h_\\theta(x_{i}) - y_{i}) $$\n",
    "\n",
    "$$ \\theta_1 :=  \\theta_1 - \\alpha \\frac{1}{m} \\sum\\limits_{i=1}^{m}\\left((h_\\theta(x_{i}) - y_{i}) x_{i}\\right)$$\n",
    "\n",
    "\n",
    "where $m$ is the training data size, $\\theta_0$ is a constant that will change along the parameters $\\theta_1$, and $x_i,y_i$ are the values of the training dataset. \n",
    "\n",
    "Note that we have separated out the two cases for $\\theta_j$ into separate equations for $\\theta_0$ and $\\theta_1$ and that for $\\theta_1$ we are multiplying $x_{i}$ at the end due to the derivative. The following is a derivation of $\\frac{\\partial}{\\partial \\theta_j}J(\\theta)$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\dfrac{\\partial}{\\partial\\theta_j}J(\\theta) & = \\dfrac{\\partial}{\\partial\\theta_j}J(\\theta)\\frac{1}{2}(h_\\theta(x)-y)^2 \\\\\n",
    "& = 2\\cdot\\frac{1}{2}(h_\\theta(x)-y)\\cdot\\dfrac{\\partial}{\\partial\\theta_j}(h_\\theta(x)-y) \\\\\n",
    "& =(h_\\theta(x)-y)\\cdot\\dfrac{\\partial}{\\partial\\theta_j}\\left(\\sum_{i=0}^n\\theta_ix_i-y\\right) \\\\\n",
    "& =(h_\\theta(x)-y)x_j\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "So, this is simply gradient descent on the original cost function $J$. This method looks at every example in the entire training set on every step, and is called **batch gradient descent**. Note that, while gradient descent can be susceptible to local minima in general, the optimization problem we have posed here for linear regression has only one global, and no other local, optima; thus gradient descent always converges (assuming the learning rate α is not too large) to the global minimum. Indeed, $J$ is a convex quadratic function. Here is an example of gradient descent as it is run to minimize a quadratic function.\n",
    "\n",
    "![](../pictures/gradient_4.png)\n",
    "\n",
    "The ellipses shown above are the contours of a quadratic function. Also shown is the trajectory taken by gradient descent, which was initialized at (48,30). The x’s in the figure (joined by straight lines) mark the successive values of θ that gradient descent went through as it converged to its minimum.\n",
    "\n",
    "\n",
    "**On a side note, we should adjust our parameter $\\alpha$ to ensure that the gradient descent algorithm converges in a reasonable time. Failure to converge or too much time to obtain the minimum value imply that our step size is wrong.**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate \n",
    "\n",
    "The parameter $\\alpha$, the learning rate, affects the time needed for the gradient descent to converge. Inability to converge or huge time to converge ussually means that the alpha parameter is wrong.\n",
    "\n",
    "The following images depict two cases of wrong learning rate. In the first case the learning rate $\\alpha$ is very small that leads the to many algorithm repitions which will take very long time to converge. In the second image, the learning rate $\\alpha$ is very big and the algorithm can't converge.\n",
    "\n",
    "\n",
    "<img src=\"../pictures/learning_rate1.png\" alt=\"notation\" width=\"500\" height=\"500\" />\n",
    "\n",
    "\n",
    "<img src=\"../pictures/learning_rate2.png\" alt=\"notation\" width=\"500\" height=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check Stohastic Gradient Descent & Mini-Batch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Linear Regression ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n"
     ]
    }
   ],
   "source": [
    "# Load the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "print(diabetes.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learn more on [diabetes dataset](https://scikit-learn.org/stable/datasets/index.html#diabetes-dataset) ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.06169621]\n",
      " [-0.05147406]\n",
      " [ 0.04445121]\n",
      " [-0.01159501]\n",
      " [-0.03638469]\n",
      " [-0.04069594]\n",
      " [-0.04716281]\n",
      " [-0.00189471]\n",
      " [ 0.06169621]\n",
      " [ 0.03906215]\n",
      " [-0.08380842]\n",
      " [ 0.01750591]\n",
      " [-0.02884001]\n",
      " [-0.00189471]\n",
      " [-0.02560657]\n",
      " [-0.01806189]\n",
      " [ 0.04229559]\n",
      " [ 0.01211685]\n",
      " [-0.0105172 ]\n",
      " [-0.01806189]\n",
      " [-0.05686312]\n",
      " [-0.02237314]\n",
      " [-0.00405033]\n",
      " [ 0.06061839]\n",
      " [ 0.03582872]\n",
      " [-0.01267283]\n",
      " [-0.07734155]\n",
      " [ 0.05954058]\n",
      " [-0.02129532]\n",
      " [-0.00620595]\n",
      " [ 0.04445121]\n",
      " [-0.06548562]\n",
      " [ 0.12528712]\n",
      " [-0.05039625]\n",
      " [-0.06332999]\n",
      " [-0.03099563]\n",
      " [ 0.02289497]\n",
      " [ 0.01103904]\n",
      " [ 0.07139652]\n",
      " [ 0.01427248]\n",
      " [-0.00836158]\n",
      " [-0.06764124]\n",
      " [-0.0105172 ]\n",
      " [-0.02345095]\n",
      " [ 0.06816308]\n",
      " [-0.03530688]\n",
      " [-0.01159501]\n",
      " [-0.0730303 ]\n",
      " [-0.04177375]\n",
      " [ 0.01427248]\n",
      " [-0.00728377]\n",
      " [ 0.0164281 ]\n",
      " [-0.00943939]\n",
      " [-0.01590626]\n",
      " [ 0.0250506 ]\n",
      " [-0.04931844]\n",
      " [ 0.04121778]\n",
      " [-0.06332999]\n",
      " [-0.06440781]\n",
      " [-0.02560657]\n",
      " [-0.00405033]\n",
      " [ 0.00457217]\n",
      " [-0.00728377]\n",
      " [-0.0374625 ]\n",
      " [-0.02560657]\n",
      " [-0.02452876]\n",
      " [-0.01806189]\n",
      " [-0.01482845]\n",
      " [-0.02991782]\n",
      " [-0.046085  ]\n",
      " [-0.06979687]\n",
      " [ 0.03367309]\n",
      " [-0.00405033]\n",
      " [-0.02021751]\n",
      " [ 0.00241654]\n",
      " [-0.03099563]\n",
      " [ 0.02828403]\n",
      " [-0.03638469]\n",
      " [-0.05794093]\n",
      " [-0.0374625 ]\n",
      " [ 0.01211685]\n",
      " [-0.02237314]\n",
      " [-0.03530688]\n",
      " [ 0.00996123]\n",
      " [-0.03961813]\n",
      " [ 0.07139652]\n",
      " [-0.07518593]\n",
      " [-0.00620595]\n",
      " [-0.04069594]\n",
      " [-0.04824063]\n",
      " [-0.02560657]\n",
      " [ 0.0519959 ]\n",
      " [ 0.00457217]\n",
      " [-0.06440781]\n",
      " [-0.01698407]\n",
      " [-0.05794093]\n",
      " [ 0.00996123]\n",
      " [ 0.08864151]\n",
      " [-0.00512814]\n",
      " [-0.06440781]\n",
      " [ 0.01750591]\n",
      " [-0.04500719]\n",
      " [ 0.02828403]\n",
      " [ 0.04121778]\n",
      " [ 0.06492964]\n",
      " [-0.03207344]\n",
      " [-0.07626374]\n",
      " [ 0.04984027]\n",
      " [ 0.04552903]\n",
      " [-0.00943939]\n",
      " [-0.03207344]\n",
      " [ 0.00457217]\n",
      " [ 0.02073935]\n",
      " [ 0.01427248]\n",
      " [ 0.11019775]\n",
      " [ 0.00133873]\n",
      " [ 0.05846277]\n",
      " [-0.02129532]\n",
      " [-0.0105172 ]\n",
      " [-0.04716281]\n",
      " [ 0.00457217]\n",
      " [ 0.01750591]\n",
      " [ 0.08109682]\n",
      " [ 0.0347509 ]\n",
      " [ 0.02397278]\n",
      " [-0.00836158]\n",
      " [-0.06117437]\n",
      " [-0.00189471]\n",
      " [-0.06225218]\n",
      " [ 0.0164281 ]\n",
      " [ 0.09618619]\n",
      " [-0.06979687]\n",
      " [-0.02129532]\n",
      " [-0.05362969]\n",
      " [ 0.0433734 ]\n",
      " [ 0.05630715]\n",
      " [-0.0816528 ]\n",
      " [ 0.04984027]\n",
      " [ 0.11127556]\n",
      " [ 0.06169621]\n",
      " [ 0.01427248]\n",
      " [ 0.04768465]\n",
      " [ 0.01211685]\n",
      " [ 0.00564998]\n",
      " [ 0.04660684]\n",
      " [ 0.12852056]\n",
      " [ 0.05954058]\n",
      " [ 0.09295276]\n",
      " [ 0.01535029]\n",
      " [-0.00512814]\n",
      " [ 0.0703187 ]\n",
      " [-0.00405033]\n",
      " [-0.00081689]\n",
      " [-0.04392938]\n",
      " [ 0.02073935]\n",
      " [ 0.06061839]\n",
      " [-0.0105172 ]\n",
      " [-0.03315126]\n",
      " [-0.06548562]\n",
      " [ 0.0433734 ]\n",
      " [-0.06225218]\n",
      " [ 0.06385183]\n",
      " [ 0.03043966]\n",
      " [ 0.07247433]\n",
      " [-0.0191397 ]\n",
      " [-0.06656343]\n",
      " [-0.06009656]\n",
      " [ 0.06924089]\n",
      " [ 0.05954058]\n",
      " [-0.02668438]\n",
      " [-0.02021751]\n",
      " [-0.046085  ]\n",
      " [ 0.07139652]\n",
      " [-0.07949718]\n",
      " [ 0.00996123]\n",
      " [-0.03854032]\n",
      " [ 0.01966154]\n",
      " [ 0.02720622]\n",
      " [-0.00836158]\n",
      " [-0.01590626]\n",
      " [ 0.00457217]\n",
      " [-0.04285156]\n",
      " [ 0.00564998]\n",
      " [-0.03530688]\n",
      " [ 0.02397278]\n",
      " [-0.01806189]\n",
      " [ 0.04229559]\n",
      " [-0.0547075 ]\n",
      " [-0.00297252]\n",
      " [-0.06656343]\n",
      " [-0.01267283]\n",
      " [-0.04177375]\n",
      " [-0.03099563]\n",
      " [-0.00512814]\n",
      " [-0.05901875]\n",
      " [ 0.0250506 ]\n",
      " [-0.046085  ]\n",
      " [ 0.00349435]\n",
      " [ 0.05415152]\n",
      " [-0.04500719]\n",
      " [-0.05794093]\n",
      " [-0.05578531]\n",
      " [ 0.00133873]\n",
      " [ 0.03043966]\n",
      " [ 0.00672779]\n",
      " [ 0.04660684]\n",
      " [ 0.02612841]\n",
      " [ 0.04552903]\n",
      " [ 0.04013997]\n",
      " [-0.01806189]\n",
      " [ 0.01427248]\n",
      " [ 0.03690653]\n",
      " [ 0.00349435]\n",
      " [-0.07087468]\n",
      " [-0.03315126]\n",
      " [ 0.09403057]\n",
      " [ 0.03582872]\n",
      " [ 0.03151747]\n",
      " [-0.06548562]\n",
      " [-0.04177375]\n",
      " [-0.03961813]\n",
      " [-0.03854032]\n",
      " [-0.02560657]\n",
      " [-0.02345095]\n",
      " [-0.06656343]\n",
      " [ 0.03259528]\n",
      " [-0.046085  ]\n",
      " [-0.02991782]\n",
      " [-0.01267283]\n",
      " [-0.01590626]\n",
      " [ 0.07139652]\n",
      " [-0.03099563]\n",
      " [ 0.00026092]\n",
      " [ 0.03690653]\n",
      " [ 0.03906215]\n",
      " [-0.01482845]\n",
      " [ 0.00672779]\n",
      " [-0.06871905]\n",
      " [-0.00943939]\n",
      " [ 0.01966154]\n",
      " [ 0.07462995]\n",
      " [-0.00836158]\n",
      " [-0.02345095]\n",
      " [-0.046085  ]\n",
      " [ 0.05415152]\n",
      " [-0.03530688]\n",
      " [-0.03207344]\n",
      " [-0.0816528 ]\n",
      " [ 0.04768465]\n",
      " [ 0.06061839]\n",
      " [ 0.05630715]\n",
      " [ 0.09834182]\n",
      " [ 0.05954058]\n",
      " [ 0.03367309]\n",
      " [ 0.05630715]\n",
      " [-0.06548562]\n",
      " [ 0.16085492]\n",
      " [-0.05578531]\n",
      " [-0.02452876]\n",
      " [-0.03638469]\n",
      " [-0.00836158]\n",
      " [-0.04177375]\n",
      " [ 0.12744274]\n",
      " [-0.07734155]\n",
      " [ 0.02828403]\n",
      " [-0.02560657]\n",
      " [-0.06225218]\n",
      " [-0.00081689]\n",
      " [ 0.08864151]\n",
      " [-0.03207344]\n",
      " [ 0.03043966]\n",
      " [ 0.00888341]\n",
      " [ 0.00672779]\n",
      " [-0.02021751]\n",
      " [-0.02452876]\n",
      " [-0.01159501]\n",
      " [ 0.02612841]\n",
      " [-0.05901875]\n",
      " [-0.03638469]\n",
      " [-0.02452876]\n",
      " [ 0.01858372]\n",
      " [-0.0902753 ]\n",
      " [-0.00512814]\n",
      " [-0.05255187]\n",
      " [-0.02237314]\n",
      " [-0.02021751]\n",
      " [-0.0547075 ]\n",
      " [-0.00620595]\n",
      " [-0.01698407]\n",
      " [ 0.05522933]\n",
      " [ 0.07678558]\n",
      " [ 0.01858372]\n",
      " [-0.02237314]\n",
      " [ 0.09295276]\n",
      " [-0.03099563]\n",
      " [ 0.03906215]\n",
      " [-0.06117437]\n",
      " [-0.00836158]\n",
      " [-0.0374625 ]\n",
      " [-0.01375064]\n",
      " [ 0.07355214]\n",
      " [-0.02452876]\n",
      " [ 0.03367309]\n",
      " [ 0.0347509 ]\n",
      " [-0.03854032]\n",
      " [-0.03961813]\n",
      " [-0.00189471]\n",
      " [-0.03099563]\n",
      " [-0.046085  ]\n",
      " [ 0.00133873]\n",
      " [ 0.06492964]\n",
      " [ 0.04013997]\n",
      " [-0.02345095]\n",
      " [ 0.05307371]\n",
      " [ 0.04013997]\n",
      " [-0.02021751]\n",
      " [ 0.01427248]\n",
      " [-0.03422907]\n",
      " [ 0.00672779]\n",
      " [ 0.00457217]\n",
      " [ 0.03043966]\n",
      " [ 0.0519959 ]\n",
      " [ 0.06169621]\n",
      " [-0.00728377]\n",
      " [ 0.00564998]\n",
      " [ 0.05415152]\n",
      " [-0.00836158]\n",
      " [ 0.114509  ]\n",
      " [ 0.06708527]\n",
      " [-0.05578531]\n",
      " [ 0.03043966]\n",
      " [-0.02560657]\n",
      " [ 0.10480869]\n",
      " [-0.00620595]\n",
      " [-0.04716281]\n",
      " [-0.04824063]\n",
      " [ 0.08540807]\n",
      " [-0.01267283]\n",
      " [-0.03315126]\n",
      " [-0.00728377]\n",
      " [-0.01375064]\n",
      " [ 0.05954058]\n",
      " [ 0.02181716]\n",
      " [ 0.01858372]\n",
      " [-0.01159501]\n",
      " [-0.00297252]\n",
      " [ 0.01750591]\n",
      " [-0.02991782]\n",
      " [-0.02021751]\n",
      " [-0.05794093]\n",
      " [ 0.06061839]\n",
      " [-0.04069594]\n",
      " [-0.07195249]\n",
      " [-0.05578531]\n",
      " [ 0.04552903]\n",
      " [-0.00943939]\n",
      " [-0.03315126]\n",
      " [ 0.04984027]\n",
      " [-0.08488624]\n",
      " [ 0.00564998]\n",
      " [ 0.02073935]\n",
      " [-0.00728377]\n",
      " [ 0.10480869]\n",
      " [-0.02452876]\n",
      " [-0.00620595]\n",
      " [-0.03854032]\n",
      " [ 0.13714305]\n",
      " [ 0.17055523]\n",
      " [ 0.00241654]\n",
      " [ 0.03798434]\n",
      " [-0.05794093]\n",
      " [-0.00943939]\n",
      " [-0.02345095]\n",
      " [-0.0105172 ]\n",
      " [-0.03422907]\n",
      " [-0.00297252]\n",
      " [ 0.06816308]\n",
      " [ 0.00996123]\n",
      " [ 0.00241654]\n",
      " [-0.03854032]\n",
      " [ 0.02612841]\n",
      " [-0.08919748]\n",
      " [ 0.06061839]\n",
      " [-0.02884001]\n",
      " [-0.02991782]\n",
      " [-0.0191397 ]\n",
      " [-0.04069594]\n",
      " [ 0.01535029]\n",
      " [-0.02452876]\n",
      " [ 0.00133873]\n",
      " [ 0.06924089]\n",
      " [-0.06979687]\n",
      " [-0.02991782]\n",
      " [-0.046085  ]\n",
      " [ 0.01858372]\n",
      " [ 0.00133873]\n",
      " [-0.03099563]\n",
      " [-0.00405033]\n",
      " [ 0.01535029]\n",
      " [ 0.02289497]\n",
      " [ 0.04552903]\n",
      " [-0.04500719]\n",
      " [-0.03315126]\n",
      " [ 0.097264  ]\n",
      " [ 0.05415152]\n",
      " [ 0.12313149]\n",
      " [-0.08057499]\n",
      " [ 0.09295276]\n",
      " [-0.05039625]\n",
      " [-0.01159501]\n",
      " [-0.0277622 ]\n",
      " [ 0.05846277]\n",
      " [ 0.08540807]\n",
      " [-0.00081689]\n",
      " [ 0.00672779]\n",
      " [ 0.00888341]\n",
      " [ 0.08001901]\n",
      " [ 0.07139652]\n",
      " [-0.02452876]\n",
      " [-0.0547075 ]\n",
      " [-0.03638469]\n",
      " [ 0.0164281 ]\n",
      " [ 0.07786339]\n",
      " [-0.03961813]\n",
      " [ 0.01103904]\n",
      " [-0.04069594]\n",
      " [-0.03422907]\n",
      " [ 0.00564998]\n",
      " [ 0.08864151]\n",
      " [-0.03315126]\n",
      " [-0.05686312]\n",
      " [-0.03099563]\n",
      " [ 0.05522933]\n",
      " [-0.06009656]\n",
      " [ 0.00133873]\n",
      " [-0.02345095]\n",
      " [-0.07410811]\n",
      " [ 0.01966154]\n",
      " [-0.01590626]\n",
      " [-0.01590626]\n",
      " [ 0.03906215]\n",
      " [-0.0730303 ]]\n"
     ]
    }
   ],
   "source": [
    "# Use only one feature\n",
    "diabetes_X = diabetes.data[:, np.newaxis, 2]\n",
    "print(diabetes_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[233.  91. 111. 152. 120.  67. 310.  94. 183.  66. 173.  72.  49.  64.\n",
      "  48. 178. 104. 132. 220.  57.]\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training/testing sets\n",
    "diabetes_X_train = diabetes_X[:-20]\n",
    "diabetes_X_test = diabetes_X[-20:]\n",
    "# print(diabetes_X_train)\n",
    "# Split the targets into training/testing sets\n",
    "diabetes_y_train = diabetes.target[:-20]\n",
    "diabetes_y_test = diabetes.target[-20:]\n",
    "print(diabetes_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[233.  91. 111. 152. 120.  67. 310.  94. 183.  66. 173.  72.  49.  64.\n",
      "  48. 178. 104. 132. 220.  57.]\n",
      "[225.9732401  115.74763374 163.27610621 114.73638965 120.80385422\n",
      " 158.21988574 236.08568105 121.81509832  99.56772822 123.83758651\n",
      " 204.73711411  96.53399594 154.17490936 130.91629517  83.3878227\n",
      " 171.36605897 137.99500384 137.99500384 189.56845268  84.3990668 ]\n"
     ]
    }
   ],
   "source": [
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "regr.fit(diabetes_X_train, diabetes_y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "diabetes_y_pred = regr.predict(diabetes_X_test)\n",
    "print(diabetes_y_test)\n",
    "print(diabetes_y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [938.23786125]\n",
      "Mean squared error: 2548.07\n",
      "Variance score: 0.47\n"
     ]
    }
   ],
   "source": [
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(diabetes_y_test, diabetes_y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(diabetes_y_test, diabetes_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot outputs\n",
    "plt.scatter(diabetes_X_test[:,:1], diabetes_y_test,  color='black')\n",
    "plt.plot(diabetes_X_test[:,:1], diabetes_y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.xticks(diabetes_X_test)\n",
    "plt.yticks(diabetes_y_test)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}